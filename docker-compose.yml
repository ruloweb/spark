version: '3'

services:

  spark_master:
    image: ruloweb/spark:2.1.3
    ports:
      - 8080:8080
      - 7077:7077
    networks:
      spark:
        aliases:
          - master
    entrypoint:
      - spark-class
      - org.apache.spark.deploy.master.Master
    volumes:
      - "./core-site.xml:/usr/local/spark-2.1.3-bin-hadoop2.7/conf/core-site.xml"
      - "./hive-site.xml:/usr/local/spark-2.1.3-bin-hadoop2.7/conf/hive-site.xml"

  spark_worker:
    image: ruloweb/spark:2.1.3
    networks:
      - spark
    entrypoint:
      - spark-class
      - org.apache.spark.deploy.worker.Worker
      - master:7077
    volumes:
      - "./core-site.xml:/usr/local/spark-2.1.3-bin-hadoop2.7/conf/core-site.xml"
      - "./hive-site.xml:/usr/local/spark-2.1.3-bin-hadoop2.7/conf/hive-site.xml"

  name_node:
    image: ruloweb/hadoop:2.7.6
    command: [
      "bash",
      "-c",
      "hdfs namenode -format -nonInteractive ; exec hdfs namenode"
    ]
    volumes:
      - "./core-site.xml:/usr/local/hadoop-2.7.6/etc/hadoop/core-site.xml"
      - "./hdfs-site.xml:/usr/local/hadoop-2.7.6/etc/hadoop/hdfs-site.xml"
      - /data
    ports:
      - 8020:8020
      - 50070:50070
    networks:
      spark:
        aliases:
          - hdfs

  data_node:
    image: ruloweb/hadoop:2.7.6
    command: [
      "hdfs",
      "datanode"
    ]
    volumes:
      - "./core-site.xml:/usr/local/hadoop-2.7.6/etc/hadoop/core-site.xml"
      - "./hdfs-site.xml:/usr/local/hadoop-2.7.6/etc/hadoop/hdfs-site.xml"
      - /data
    ports:
      - 50075
    networks:
      - spark

  hive:
    image: ruloweb/hive2:2.3.3
    volumes:
      - "./hive:/data"
    networks:
      spark:
        aliases:
          - hive

networks:
  spark:
